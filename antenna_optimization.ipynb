{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb86ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ml_dataset_with_fom.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load original CST simulation data\n",
    "df = pd.read_csv(\"ml_dataset_with_fom.csv\")  # Make sure the file is in the same folder\n",
    "\n",
    "# Filter for both frequency bands\n",
    "band1 = df[(df[\"Frequency (GHz)\"] >= 2.4) & (df[\"Frequency (GHz)\"] <= 3.0)]\n",
    "band2 = df[(df[\"Frequency (GHz)\"] >= 5.15) & (df[\"Frequency (GHz)\"] <= 5.6)]\n",
    "group_cols = ['w', 'w1', 'l21', 'l22', 'w2']\n",
    "\n",
    "band1[\"abs_S11\"] = band1[\"S11 Magnitude\"].abs()\n",
    "band2[\"abs_S11\"] = band2[\"S11 Magnitude\"].abs()\n",
    "\n",
    "fom1 = band1.groupby(group_cols)[\"abs_S11\"].sum().reset_index()\n",
    "fom2 = band2.groupby(group_cols)[\"abs_S11\"].sum().reset_index()\n",
    "\n",
    "fom_total = pd.merge(fom1, fom2, on=group_cols, suffixes=(\"_band1\", \"_band2\"))\n",
    "fom_total[\"FOM\"] = fom_total[\"abs_S11_band1\"] + fom_total[\"abs_S11_band2\"]\n",
    "ml_data = fom_total[group_cols + [\"FOM\"]]\n",
    "ml_data.to_csv(\"ml_dataset_with_fom.csv\", index=False)\n",
    "print(\"FOM column added and saved to 'ml_dataset_with_fom.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ml_dataset_with_fom.csv')\n",
    "\n",
    "# Define input features and target\n",
    "X = data[['l21', 'l22', 'w1', 'w2', 'w']]\n",
    "y = data['FOM']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = LassoCV(cv=5, random_state=42).fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "lasso_r2 = r2_score(y_test, y_pred_lasso)\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "\n",
    "# Improved ANN (MLP Regressor)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "ann_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(50, 25),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=2000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ann_model.fit(X_train_scaled, y_train)\n",
    "y_pred_ann = ann_model.predict(X_test_scaled)\n",
    "ann_r2 = r2_score(y_test, y_pred_ann)\n",
    "ann_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ann))\n",
    "\n",
    "\n",
    "# k-Nearest Neighbors Regression\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "knn_r2 = r2_score(y_test, y_pred_knn)\n",
    "knn_rmse = np.sqrt(mean_squared_error(y_test, y_pred_knn))\n",
    "\n",
    "# Find Max FOM and Corresponding Dimensions\n",
    "max_lasso_idx = y_test.index[y_pred_lasso.argmax()]\n",
    "lasso_best_dims = X_test.loc[max_lasso_idx]\n",
    "\n",
    "max_ann_idx = y_test.index[y_pred_ann.argmax()]\n",
    "ann_best_dims = X_test.loc[max_ann_idx]\n",
    "\n",
    "max_knn_idx = y_test.index[y_pred_knn.argmax()]\n",
    "knn_best_dims = X_test.loc[max_knn_idx]\n",
    "\n",
    "# Compute Average Best Dimensions\n",
    "average_best_dims = pd.DataFrame([lasso_best_dims, ann_best_dims, knn_best_dims]).mean()\n",
    "\n",
    "# Print Results\n",
    "print(f\"\\nLasso R² score: {lasso_r2:.4f}\")\n",
    "print(f\"ANN R² score: {ann_r2:.4f}\")\n",
    "print(f\"kNN R² score: {knn_r2:.4f}\")\n",
    "\n",
    "# Print Results\n",
    "print(f\"\\nLasso RMSE score: {lasso_rmse:.4f}\")\n",
    "print(f\"ANN RMSE score: {ann_rmse:.4f}\")\n",
    "print(f\"kNN RMSE score: {knn_rmse:.4f}\")\n",
    "\n",
    "print(\"\\n Lasso Best Dimensions:\\n\", lasso_best_dims)\n",
    "print(\"\\n ANN Best Dimensions:\\n\", ann_best_dims)\n",
    "print(\"\\n kNN Best Dimensions:\\n\", knn_best_dims)\n",
    "\n",
    "print(\"\\n Averaged Best Dimensions (Consensus Recommendation):\\n\", average_best_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('/content/drive/MyDrive/Datasets/ml_dataset_with_fom.csv')\n",
    "\n",
    "# Define input features and target\n",
    "X = data[['l21', 'l22', 'w1', 'w2', 'w']]\n",
    "y = data['FOM']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create quadratic features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "# Get feature names\n",
    "feature_names = poly.get_feature_names_out(input_features=X.columns)\n",
    "\n",
    "# Get coefficients and intercept\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Build the equation string\n",
    "terms = [f\"{intercept:.4f}\"] + [\n",
    "    f\"{coef:.4f}*{name}\" for coef, name in zip(coefficients[1:], feature_names[1:])\n",
    "]\n",
    "\n",
    "equation = \" + \".join(terms)\n",
    "\n",
    "# Print the equation\n",
    "print(\"\\nPolynomial Regression Equation:\")\n",
    "print(f\"FOM = {equation}\")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test_poly)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model RMSE: {rmse:.4f}\")\n",
    "print(f\"Model R²: {r2:.4f}\")\n",
    "\n",
    "# Function to predict FOM for new design points\n",
    "def predict_fom(design_params):\n",
    "    # Create a DataFrame with correct feature names\n",
    "    columns = ['l21', 'l22', 'w1', 'w2', 'w']\n",
    "    design_df = pd.DataFrame([design_params], columns=columns)\n",
    "    design_poly = poly.transform(design_df)\n",
    "    return model.predict(design_poly)[0]\n",
    "\n",
    "\n",
    "def trust_region_optimizer(initial_design, model, poly,\n",
    "                           bounds,\n",
    "                           initial_radius=0.1,\n",
    "                           min_radius=1e-3,\n",
    "                           max_iter=50):\n",
    "    current = initial_design\n",
    "    radius = initial_radius\n",
    "    history = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        candidates = []\n",
    "        for _ in range(100):\n",
    "            noise = np.random.uniform(-radius, radius, size=current.shape)\n",
    "            candidate = np.clip(current + noise,\n",
    "                                [b[0] for b in bounds],\n",
    "                                [b[1] for b in bounds])\n",
    "            candidates.append(candidate)\n",
    "\n",
    "        candidates = np.array(candidates)\n",
    "        preds = np.array([predict_fom(c) for c in candidates])\n",
    "\n",
    "        best_idx = np.argmax(preds)\n",
    "        best_candidate = candidates[best_idx]\n",
    "        best_pred_fom = preds[best_idx]\n",
    "        current_pred_fom = predict_fom(current)\n",
    "\n",
    "        improvement = best_pred_fom - current_pred_fom\n",
    "        if improvement > 0:\n",
    "            current = best_candidate\n",
    "            radius *= 1.2\n",
    "        else:\n",
    "            radius *= 0.5\n",
    "\n",
    "        history.append((current.copy(), best_pred_fom, radius))\n",
    "\n",
    "        print(f\"Step {i+1}: FOM={best_pred_fom:.4f}, Radius={radius:.4f}\")\n",
    "\n",
    "        if radius < min_radius:\n",
    "            print(\"Converged: Trust region too small.\")\n",
    "            break\n",
    "\n",
    "    return current, history\n",
    "\n",
    "# Starting design (replace with something valid for your case)\n",
    "initial_design = np.array([6.96, 6.8, 1.0, 3.5, 3.33])\n",
    "\n",
    "# Parameter bounds (update as needed based on your domain)\n",
    "bounds = [(6.3, 7.3), (6.3, 7.3), (1, 3.5), (1, 3.5), (1, 3.5)]\n",
    "\n",
    "# Run optimization\n",
    "best_design, history = trust_region_optimizer(initial_design, model, poly, bounds)\n",
    "\n",
    "print(\"Best design found:\", best_design)\n",
    "\n",
    "# Calculate FOM for the best design\n",
    "best_fom = predict_fom(best_design)\n",
    "print(f\"Predicted FOM for best design: {best_fom:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
